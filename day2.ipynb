{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-24T05:52:50.939042Z",
     "start_time": "2025-06-24T05:52:33.520363Z"
    }
   },
   "cell_type": "code",
   "source": [
    "%%capture --no-stderr\n",
    "%pip install langchain langchain-openai langchain-openai langchain_chroma langchain-text-splitters langchain_community"
   ],
   "id": "958538816066f6dd",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-06-24T07:31:26.346407Z",
     "start_time": "2025-06-24T07:31:25.924891Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "langchain_key = os.getenv(\"LANGCHAIN_API_KEY\")\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")"
   ],
   "id": "initial_id",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-24T07:31:33.452808Z",
     "start_time": "2025-06-24T07:31:27.149269Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import bs4\n",
    "from langchain import hub\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "import bs4\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "\n",
    "def get_retriever_from_blog_posts():\n",
    "    embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "    vectorstore = Chroma(embedding_function=embeddings)\n",
    "\n",
    "    urls = [\n",
    "        \"https://lilianweng.github.io/posts/2023-06-23-agent/\",\n",
    "        \"https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/\",\n",
    "        \"https://lilianweng.github.io/posts/2023-10-25-adv-attack-llm/\",\n",
    "    ]\n",
    "\n",
    "    for url in urls:\n",
    "        loader = WebBaseLoader(\n",
    "            web_paths=(url,),\n",
    "            bs_kwargs=dict(\n",
    "                parse_only=bs4.SoupStrainer(\n",
    "                    class_=(\"post-content\", \"post-title\", \"post-header\")\n",
    "                )\n",
    "            ),\n",
    "        )\n",
    "\n",
    "        docs = loader.load()\n",
    "        text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=100)\n",
    "        splits = text_splitter.split_documents(docs)\n",
    "        vectorstore.add_documents(splits)\n",
    "\n",
    "        retriever = vectorstore.as_retriever(\n",
    "            search_type=\"similarity\",\n",
    "            search_kwargs={\"k\": 6}\n",
    "        )\n",
    "\n",
    "    return retriever\n",
    "\n",
    "\n",
    "retriever = get_retriever_from_blog_posts()\n",
    "\n",
    "docs_retrived = retriever.invoke(\"agent memory\")\n",
    "docs_retrived\n"
   ],
   "id": "d0728678ee8549e0",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Document(id='27eb0525-bbb2-4a5f-9310-c4758995a26a', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='The design of generative agents combines LLM with memory, planning and reflection mechanisms to enable agents to behave conditioned on past experience, as well as to interact with other agents.'),\n",
       " Document(id='d4a0c8f8-84c4-4533-bf04-b4b2cb67a165', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='Memory stream: is a long-term memory module (external database) that records a comprehensive list of agents’ experience in natural language.\\n\\nEach element is an observation, an event directly provided by the agent.\\n- Inter-agent communication can trigger new natural language statements.\\n\\n\\nRetrieval model: surfaces the context to inform the agent’s behavior, according to relevance, recency and importance.'),\n",
       " Document(id='e9fa6ab0-2e98-4641-a632-29d92e6a950c', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview#\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:'),\n",
       " Document(id='ec1a6735-a3a5-448c-b290-fd983ae12782', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='Tool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\n\\nOverview of a LLM-powered autonomous agent system.'),\n",
       " Document(id='7cc1594d-2cc2-4823-8725-1006be6601fb', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='Memory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use'),\n",
       " Document(id='805d8f3e-68be-4713-8641-2a3df77ee3dd', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='Reliability of natural language interface: Current agent system relies on natural language as an interface between LLMs and external components such as memory and tools. However, the reliability of model outputs is questionable, as LLMs may make formatting errors and occasionally exhibit rebellious behavior (e.g. refuse to follow an instruction). Consequently, much of the agent demo code focuses on parsing model output.\\n\\n\\nCitation#\\nCited as:')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-24T07:31:45.709215Z",
     "start_time": "2025-06-24T07:31:33.457972Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 5-2 참고 코드\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class RelevanceResult(BaseModel):\n",
    "    relevance: bool = Field(description=\"query relevance to the text chunk\")\n",
    "\n",
    "\n",
    "def is_relevant(query, docs):\n",
    "    parser = JsonOutputParser(pydantic_object=RelevanceResult)\n",
    "\n",
    "    prompt = PromptTemplate(\n",
    "        template=\"\"\"\n",
    "    You are an expert at evaluating information retrieval quality.\n",
    "    Given a user query and a retrieved text chunk, determine if the chunk is relevant to the query.\n",
    "\n",
    "    # Format: {format_instructions}\n",
    "    # User Query: {query}\n",
    "    # Retrieved Chunk: {text}\n",
    "        \"\"\",\n",
    "        partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
    "        input_variables=[\"query\", \"text\"],\n",
    "    )\n",
    "\n",
    "    chain = prompt | llm | parser\n",
    "    return chain.invoke({\"query\": query, \"text\": docs})\n",
    "\n",
    "# for all fail\n",
    "for doc in docs_retrived:\n",
    "    print(is_relevant(\"카카오\", doc.page_content))\n",
    "\n",
    "for doc in docs_retrived:\n",
    "    print(\"\\n\\n##########\",is_relevant(\"agent memory\", doc.page_content), doc.page_content)\n",
    "\n",
    "\n",
    "def get_only_relevance_docs(query, retriever):\n",
    "    docs = retriever.invoke(query)\n",
    "    relevant_docs = []\n",
    "    for doc in docs:\n",
    "        result = is_relevant(query, doc.page_content)\n",
    "        if result['relevance']:\n",
    "            relevant_docs.append(doc)\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in relevant_docs)\n",
    "\n"
   ],
   "id": "1c6c6ebe1c4d72e2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'relevance': False}\n",
      "{'relevance': False}\n",
      "{'relevance': False}\n",
      "{'relevance': False}\n",
      "{'relevance': False}\n",
      "{'relevance': False}\n",
      "\n",
      "\n",
      "########## {'relevance': True} The design of generative agents combines LLM with memory, planning and reflection mechanisms to enable agents to behave conditioned on past experience, as well as to interact with other agents.\n",
      "\n",
      "\n",
      "########## {'relevance': True} Memory stream: is a long-term memory module (external database) that records a comprehensive list of agents’ experience in natural language.\n",
      "\n",
      "Each element is an observation, an event directly provided by the agent.\n",
      "- Inter-agent communication can trigger new natural language statements.\n",
      "\n",
      "\n",
      "Retrieval model: surfaces the context to inform the agent’s behavior, according to relevance, recency and importance.\n",
      "\n",
      "\n",
      "########## {'relevance': True} Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\n",
      "Agent System Overview#\n",
      "In a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\n",
      "\n",
      "\n",
      "########## {'relevance': False} Tool use\n",
      "\n",
      "The agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Overview of a LLM-powered autonomous agent system.\n",
      "\n",
      "\n",
      "########## {'relevance': True} Memory\n",
      "\n",
      "Short-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\n",
      "Long-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\n",
      "\n",
      "\n",
      "Tool use\n",
      "\n",
      "\n",
      "########## {'relevance': True} Reliability of natural language interface: Current agent system relies on natural language as an interface between LLMs and external components such as memory and tools. However, the reliability of model outputs is questionable, as LLMs may make formatting errors and occasionally exhibit rebellious behavior (e.g. refuse to follow an instruction). Consequently, much of the agent demo code focuses on parsing model output.\n",
      "\n",
      "\n",
      "Citation#\n",
      "Cited as:\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-24T07:31:55.866152Z",
     "start_time": "2025-06-24T07:31:49.085695Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=\"\"\"\n",
    "You are an expert assistant. Answer the following User Query using only the information provided in the Retrieved Chunk. If the Retrieved Chunk does not contain enough information to answer the query, say \"The information is not available in the provided text.\"\n",
    "\n",
    "Retrieved Chunk: {context}\n",
    "User Query: {question}\n",
    "\n",
    "Your Answer:\n",
    "    \"\"\",\n",
    "    input_variables=[\"context\", \"question\"],\n",
    ")\n",
    "\n",
    "rag_chain = (\n",
    "        {\"context\": RunnablePassthrough(), \"question\": RunnablePassthrough()}\n",
    "        | prompt\n",
    "        | llm\n",
    "        | StrOutputParser()\n",
    ")\n",
    "\n",
    "query = \"What is Task Decomposition?\"\n",
    "relevance_docs = get_only_relevance_docs(query, retriever)\n",
    "\n",
    "for chunk in rag_chain.stream({\"context\": relevance_docs, \"question\": query}):\n",
    "    print(chunk, end=\"\", flush=True)"
   ],
   "id": "3b4e50cc51075b95",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task decomposition is the process by which an agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks. It can be achieved through various methods, including simple prompting by a language model, task-specific instructions, or human inputs. Additionally, it involves planning ahead and allows the agent to reflect on and refine past actions to improve the quality of future results."
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "5173056e00d0078c"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
